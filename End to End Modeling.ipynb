{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft\n",
    "from featuretools.primitives import CumMean, Percentile\n",
    "from featuretools.selection import remove_low_information_features\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyber_df = pd.read_csv(\"CyberFLTenDays.csv\")\n",
    "cyber_df.index.name = \"log_id\"\n",
    "cyber_df.reset_index(inplace=True, drop=False)\n",
    "cyber_df['label'] = cyber_df['label'].map({'N': False, 'A': True}, na_action='ignore')\n",
    "# cyber_df_pos = cyber_df[cyber_df['label']]\n",
    "# cyber_df_neg = cyber_df[~cyber_df['label']].sample(100000)\n",
    "# cyber_df = pd.concat([cyber_df_pos, cyber_df_neg]).sort_values(['secs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: CyberLL\n",
       "  Entities:\n",
       "    log (shape = [341787, 7])\n",
       "    name_host_pairs (shape = [158354, 6])\n",
       "    sessions (shape = [25174, 4])\n",
       "  Relationships:\n",
       "    log.name_host_pair -> name_host_pairs.name_host_pair\n",
       "    name_host_pairs.session_id -> sessions.session_id"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = ft.EntitySet(\"CyberLL\")\n",
    "# create an index column\n",
    "cyber_df[\"name_host_pair\"] = cyber_df[\"src_name\"].str.cat(\n",
    "                                [cyber_df[\"dest_name\"],\n",
    "                                 cyber_df[\"src_host\"],\n",
    "                                 cyber_df[\"dest_host\"]],\n",
    "                                sep=' / ')\n",
    "cyber_df[\"session_id\"] = cyber_df[\"src_name\"].str.cat(\n",
    "                                 cyber_df[\"dest_name\"],\n",
    "                                 sep=' / ')\n",
    "\n",
    "es.entity_from_dataframe(\"log\",\n",
    "                         cyber_df,\n",
    "                         index=\"log_id\",\n",
    "                         time_index=\"secs\")\n",
    "es.normalize_entity(base_entity_id=\"log\",\n",
    "                    new_entity_id=\"name_host_pairs\",\n",
    "                    index=\"name_host_pair\",\n",
    "                    additional_variables=[\"src_name\", \"dest_name\",\n",
    "                                          \"src_host\", \"dest_host\",\n",
    "                                          #\"src_pair\",\n",
    "                                          #\"dest_pair\",\n",
    "                                          \"session_id\",\n",
    "                                          \"label\"])\n",
    "es.normalize_entity(base_entity_id=\"name_host_pairs\",\n",
    "                    new_entity_id=\"sessions\",\n",
    "                    index=\"session_id\",\n",
    "                    additional_variables=[\"dest_name\", \"src_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cutoffs(cyber_df, index_col, after_n_obs, lead, prediction_window):\n",
    "    window_start = after_n_obs + lead\n",
    "    window_end = window_start + prediction_window\n",
    "    grouped = cyber_df.groupby(index_col)[index_col].count()\n",
    "    grouped.name = \"count\"\n",
    "    min_obs = after_n_obs + lead + 1\n",
    "    enough_examples = grouped[grouped > min_obs].to_frame().reset_index()\n",
    "    enough_examples = cyber_df[cyber_df[index_col].isin(enough_examples[index_col])]\n",
    "    def get_label_and_cutoff(df):\n",
    "        cutoff = df.iloc[after_n_obs]\n",
    "        cutoff['label'] = df.iloc[window_start: window_end][\"label\"].any()\n",
    "        return cutoff\n",
    "    cutoffs = enough_examples.groupby(index_col)[[index_col, \"secs\", \"label\"]].apply(get_label_and_cutoff)\n",
    "    return cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 54 features\n",
      "Elapsed: 23:59 | Remaining: 17:42 | Progress:  58%|█████▊    || Calculated: 7667/13328 cutoff times"
     ]
    }
   ],
   "source": [
    "# features on src_name\n",
    "cutoffs = generate_cutoffs(cyber_df, \"session_id\", 3, 2, 10)\n",
    "cutoffs.shape, cutoffs['label'].value_counts()\n",
    "fm, fl = ft.dfs(entityset=es, target_entity=\"sessions\", cutoff_time=cutoffs,\n",
    "                #trans_primitives=[CumMean, Percentile],\n",
    "                verbose=True, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.sort_index(inplace=True)\n",
    "cutoffs.sort_index(inplace=True)\n",
    "fm['label'] = cutoffs['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_encoded, fl_encoded = ft.encode_features(fm, fl)\n",
    "fm_encoded, fl_encoded = remove_low_information_features(fm_encoded, fl_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(fm_encoded, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train\n",
    "y_train = X_train.pop('label')\n",
    "X_test = test\n",
    "y_test = X_test.pop('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(missing_values='NaN', strategy=\"mean\", axis=0)\n",
    "scaler = StandardScaler()\n",
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "model = Pipeline([(\"imputer\", imputer),\n",
    "                  (\"scaler\", scaler),\n",
    "                  (\"rf\", clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "    \n",
    "preds = model.predict(X_test)\n",
    "score = roc_auc_score(preds, y_test)\n",
    "print('ROC AUC Score: {:.2f}'.format(score))\n",
    "high_imp_feats = utils.feature_importances(X_train, clf, feats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
